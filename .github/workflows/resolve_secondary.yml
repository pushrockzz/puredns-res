name: PureDNS Resolution Worker (Secondary)

on:
  workflow_dispatch:
    inputs:
      primary_run_id:
        description: 'The run ID of the primary workflow for artifact correlation.'
        required: true
        type: string
      primary_github_server_url:
        description: 'The server URL of the primary GitHub instance (e.g., https://github.com)'
        required: true
        type: string 
      primary_repo:
        description: 'The owner/repo of the primary workflow'
        required: true
        type: string
      primary_repo_owner:
        description: 'The owner of the primary repository that triggered this workflow.'
        required: true
        type: string
      primary_repo_name:
        description: 'The name of the primary repository that triggered this workflow.'
        required: true
        type: string  
      chunk_package_artifact_name:
        description: 'The name of the artifact package containing all chunks and resolvers.'
        required: true
        type: string
      matrix_json:
        description: 'The JSON string representing the matrix of chunks assigned to this worker.'
        required: true
        type: string

permissions:
  contents: read
  actions: read

jobs:
  process_assigned_chunks:
    name: Process Chunk (${{ matrix.pair.chunk }})
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      max-parallel: 20
      matrix:
        pair: ${{ fromJson(github.event.inputs.matrix_json || '[]') }}
    steps:
      - name: Display Trigger Payload (Debug)
        run: |
          echo "SECONDARY WORKER: Received payload:"
          echo "Primary Repo: ${{ github.event.inputs.primary_repo }}"
          echo "Primary Run ID: ${{ github.event.inputs.primary_run_id }}"
          echo "Artifact Name: ${{ github.event.inputs.chunk_package_artifact_name }}"
          echo "---"
          echo "Assigned Chunk for this job: ${{ toJson(matrix.pair) }}"

      - name: Checkout repository
        uses: actions/checkout@v4
        with: 
            fetch-depth: 0

      - name: Setup Go
        uses: actions/setup-go@v3
        with:
          go-version: '1.23'            # or whichever version you need

      - name: Cache Go modules and build cache
        uses: actions/cache@v3
        with:
          path: |
            ~/.cache/go-build
            ~/go/pkg/mod
          key: ${{ runner.os }}-go-mod-${{ hashFiles('**/go.sum') }}
          restore-keys: |
            ${{ runner.os }}-go-mod-
            

      - name: Download Chunks Package from Primary Workflow
        env:
          GH_TOKEN: ${{ secrets.PAT_FOR_PRIMARY_ARTIFACTS_READ }}
          PRIMARY_REPO: ${{ github.event.inputs.primary_repo }}
          PRIMARY_RUN_ID: ${{ github.event.inputs.primary_run_id }}
          ARTIFACT_NAME: ${{ github.event.inputs.chunk_package_artifact_name }}          
        shell: bash
        run: |

          echo "WORKER: Downloading artifact '${{ github.event.inputs.chunk_package_artifact_name }}'..."
          
          # --- MODIFICATION: Added 'sudo' to all system commands ---
          echo "Installing GitHub CLI with root privileges..."
          sudo apt-get update -qy
          sudo apt-get install -qy curl
          
          # Use a pipe to sudo tee for writing the keyring to a protected directory
          curl -fsSL https://cli.github.com/packages/githubcli-archive-keyring.gpg | sudo tee /usr/share/keyrings/githubcli-archive-keyring.gpg > /dev/null
          
          # Use a pipe to sudo tee for writing the source list
          echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/githubcli-archive-keyring.gpg] https://cli.github.com/packages stable main" | sudo tee /etc/apt/sources.list.d/github-cli.list > /dev/null
          
          sudo apt-get update -qy
          sudo apt-get install -qy gh
          # --- END MODIFICATION ---

          # Download artifact (this command does not need sudo)
          gh run download ${{ github.event.inputs.primary_run_id }} -R ${{ github.event.inputs.primary_repo }} -n ${{ github.event.inputs.chunk_package_artifact_name }} --dir .
          
          if [ ! -d "chunks" ]; then
            echo "::error:: Artifact download failed or did not contain the 'chunks' directory."
            exit 0
          fi
          echo "Artifact downloaded successfully."
          
      - name: Ensure Tools are installed
        shell: bash
        run: |
          if ! command -v dsieve &> /dev/null; then
            echo "ðŸ› ï¸  dsieve not found; installing..."
            GO111MODULE=on go install \
             github.com/trickest/dsieve@latest
            echo "âœ… Installed dsieve to $(go env GOPATH)/bin/dsieve"
          else
            echo "âœ… dsieve already installed at $(command -v dsieve)"
          fi
         
          # Installing cut-cdn
          if ! command -v cut-cdn >/dev/null; then
            echo "Installing cut-cdnâ€¦"
            go install github.com/ImAyrix/cut-cdn@latest
          else
            echo "cut-cdn already in cache"
          fi       
          
          # Installing smap
          if ! command -v smap >/dev/null; then
            echo "Installing smapâ€¦"
            go install -v github.com/s0md3v/smap/cmd/smap@latest
          else
            echo "smap already in cache"
          fi   
          # Installing anew
          if ! command -v anew >/dev/null; then
            echo "Installing anewâ€¦"
            go install -v github.com/tomnomnom/anew@latest
          else
            echo "anew already in cache"
          fi    
      
      - name: Install preâ€‘reqs
        run: | 
          sudo apt-get update && sudo apt-get install -y jq curl

      - name: Install sanicdns
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # make sure the script is executable
          chmod +x scripts/install-sanicdns.sh
          # run the installer
          scripts/install-sanicdns.sh
     
      - name: Install ethtool & shrink NIC queues
        run: |
          sudo apt-get update -qq
          for i in {1..3}; do
            sudo DEBIAN_FRONTEND=noninteractive apt-get install -y -qq jq ethtool && break
            echo "apt install failed, retrying in 10sâ€¦" >&2
            sleep 10
          done
      
      - name: Resize NIC RSS queues
        run: |
          IFACE=$(ip route show default 2>/dev/null | awk '/default/ {print $5}' | head -n1)
          if [ -n "$IFACE" ]; then
            echo "ðŸ”§ Resizing RSS queues on $IFACE to 3..."
            sudo ethtool -L "$IFACE" combined 3 || true
          else
            echo "âš ï¸  No default interface detected; skipping RSS resize."
          fi
      
      - name: Allocate hugepages (1 GB)
        run: |
           # best-effort; if dpdk-hugepages.py isn't on PATH this will fail harmlessly
           sudo dpdk-hugepages.py --setup 2G || true

      - name: Resolve, Filter, Scan, and Sort
        id: resolve_and_sort
        shell: bash
        env:
          TERM: xterm        
        run: |
          # This entire block is a direct copy of the processing logic from the Primary workflow
          # to ensure 100% consistency in results.
          set -e
          CHUNK_FILE="${{ matrix.pair.chunk }}"
          JOB_OUTPUT_DIR="job_output"
          mkdir -p "$JOB_OUTPUT_DIR"

          echo "Processing chunk: '$CHUNK_FILE'..."
          if [ ! -s "$CHUNK_FILE" ]; then
            echo "Chunk file is empty. Exiting."
            exit 0
          fi
          
          echo "Installing resolvers.txt"

          wget -qO resolvers.txt https://raw.githubusercontent.com/and0x00/resolvers.txt/refs/heads/main/resolvers.txt          
          
          # 1. Resolve with sanicdns (and required setup)
          chmod +x scripts/install-sanicdns.sh && scripts/install-sanicdns.sh
          SANICDNS_OUT="$JOB_OUTPUT_DIR/sanicdns_output.txt"
          sudo sanicdns \
            -i "$CHUNK_FILE" -r 1000 -c 3000 \
            --resolvers resolvers.txt \
            -o "$SANICDNS_OUT" -w 4 --num-retries 7 --timeout 7000

          # 2. Filter and Process IPs
          FILTER_OUT="$JOB_OUTPUT_DIR/sanicdns_filter.txt"
          IP_LIST="$JOB_OUTPUT_DIR/ip_list.txt"
          NON_CDN_IP="$JOB_OUTPUT_DIR/non_cdn_ip.txt"
          SMAP_OUT="$JOB_OUTPUT_DIR/smap.txt"
          SUBDOMAIN_PORTS="$JOB_OUTPUT_DIR/subdomains_ports.txt"
          
          jq -r 'select(.data.answers | any(.type=="A")) | .name | rtrimstr(".")' "$SANICDNS_OUT" | anew -q "$FILTER_OUT"
          jq -r 'select(.data.answers | any(.type=="A")) | .data.answers[] | select(.type == "A") | .data' "$SANICDNS_OUT" | sort -u > "$IP_LIST"
          
          cat "$IP_LIST" | cut-cdn -ua -silent -o "$NON_CDN_IP"
          grep -Fxv -f "$NON_CDN_IP" "$IP_LIST" > "$JOB_OUTPUT_DIR/cdn_ip.txt" || true
          
          if [ -s "$NON_CDN_IP" ]; then smap -iL "$NON_CDN_IP" -oP "$SMAP_OUT"; else touch "$SMAP_OUT"; fi
          
          touch "$SUBDOMAIN_PORTS"
          chmod +x map_IP_to_HOST.py
          if [ -s "$SMAP_OUT" ]; then ./map_IP_to_HOST.py "$SANICDNS_OUT" "$SMAP_OUT" | anew -q "$SUBDOMAIN_PORTS"; fi
          if [ -s "$JOB_OUTPUT_DIR/cdn_ip.txt" ]; then ./map_IP_to_HOST.py "$SANICDNS_OUT" "$JOB_OUTPUT_DIR/cdn_ip.txt" | anew -q "$SUBDOMAIN_PORTS"; fi

          # 3. Sort results into root domain folders
          FINAL_SORTED_DIR="final_sorted"
          mkdir -p "$FINAL_SORTED_DIR"
          
          while read -r root_domain; do
            if [ -z "$root_domain" ]; then continue; fi
            mkdir -p "$FINAL_SORTED_DIR/$root_domain"
            grep -E "(^|\\.)${root_domain//./\\.}(\$|:)" "$SUBDOMAIN_PORTS" | anew -q "$FINAL_SORTED_DIR/$root_domain/subdomains_ports.txt" || true
            grep -E "(^|\\.)${root_domain//./\\.}(\$)" "$FILTER_OUT" | anew -q "$FINAL_SORTED_DIR/$root_domain/resolved_subdomains.txt" || true
          done < root_domains.txt

      - name: Upload Sorted Job Results
        uses: actions/upload-artifact@v4
        with:
          name: job-results-secondary-${{ github.event.inputs.primary_run_id }}-${{ strategy.job-index }}
          path: final_sorted/
          retention-days: 1
